{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "58553f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load and preprocess the data\n",
    "import pandas as pd\n",
    "\n",
    "# Replace file paths with the paths to the downloaded files\n",
    "orders_df = pd.read_csv(\"../datasets/olist_orders_dataset.csv\")\n",
    "order_items_df = pd.read_csv(\"../datasets/olist_order_items_dataset.csv\")\n",
    "products_df = pd.read_csv(\"../datasets/olist_products_dataset.csv\")\n",
    "reviews_df = pd.read_csv(\"../datasets/olist_order_reviews_dataset.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "28eeb9d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order_id                            0\n",
      "customer_id                         0\n",
      "order_status                        0\n",
      "order_purchase_timestamp            0\n",
      "order_approved_at                 160\n",
      "order_delivered_carrier_date     1783\n",
      "order_delivered_customer_date    2965\n",
      "order_estimated_delivery_date       0\n",
      "dtype: int64\n",
      "order_id               0\n",
      "order_item_id          0\n",
      "product_id             0\n",
      "seller_id              0\n",
      "shipping_limit_date    0\n",
      "price                  0\n",
      "freight_value          0\n",
      "dtype: int64\n",
      "product_id                      0\n",
      "product_category_name         610\n",
      "product_name_lenght           610\n",
      "product_description_lenght    610\n",
      "product_photos_qty            610\n",
      "product_weight_g                2\n",
      "product_length_cm               2\n",
      "product_height_cm               2\n",
      "product_width_cm                2\n",
      "dtype: int64\n",
      "review_id                      0\n",
      "order_id                       0\n",
      "review_score                   0\n",
      "review_comment_title       87656\n",
      "review_comment_message     58247\n",
      "review_creation_date           0\n",
      "review_answer_timestamp        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#checking for missing values \n",
    "print(orders_df.isnull().sum())\n",
    "print(order_items_df.isnull().sum())\n",
    "print(products_df.isnull().sum())\n",
    "print(reviews_df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "925d4d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute categorical data with the mode (most frequent category)\n",
    "products_df['product_category_name'].fillna(products_df['product_category_name'].mode()[0], inplace=True)\n",
    "\n",
    "# Impute numerical data with the mean\n",
    "for col in ['product_name_lenght', 'product_description_lenght', 'product_photos_qty']:\n",
    "    products_df[col].fillna(products_df[col].mean(), inplace=True)\n",
    "\n",
    "# For very few missing values in product dimensions and weight, use mean\n",
    "for col in ['product_weight_g', 'product_length_cm', 'product_height_cm', 'product_width_cm']:\n",
    "    products_df[col].fillna(products_df[col].mean(), inplace=True)\n",
    "\n",
    "# For review comments, replace missing values with 'No Comment'\n",
    "reviews_df['review_comment_title'].fillna('No Comment', inplace=True)\n",
    "reviews_df['review_comment_message'].fillna('No Comment', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6fe3beeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in Product Dataset:\n",
      "product_id                    0\n",
      "product_category_name         0\n",
      "product_name_lenght           0\n",
      "product_description_lenght    0\n",
      "product_photos_qty            0\n",
      "product_weight_g              0\n",
      "product_length_cm             0\n",
      "product_height_cm             0\n",
      "product_width_cm              0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in Review Dataset:\n",
      "review_id                  0\n",
      "order_id                   0\n",
      "review_score               0\n",
      "review_comment_title       0\n",
      "review_comment_message     0\n",
      "review_creation_date       0\n",
      "review_answer_timestamp    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#after handling the missing values we recheck the datasets to ensure that all missing values have been appropriately addressed\n",
    "print(\"Missing values in Product Dataset:\")\n",
    "print(products_df.isnull().sum())\n",
    "\n",
    "print(\"\\nMissing values in Review Dataset:\")\n",
    "print(reviews_df.isnull().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c905bdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging the datasets\n",
    "# Example of merging orders and order items\n",
    "full_order_df = pd.merge(orders_df, order_items_df, on='order_id', how='left')\n",
    "\n",
    "# Example of merging the full order data with product information\n",
    "full_order_product_df = pd.merge(full_order_df, products_df, on='product_id', how='left')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c3a053b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating new features \n",
    "#based on the merged data, we want to create new features that can help in our analysis or model building\n",
    "\n",
    "full_order_product_df['total_value'] = full_order_product_df['price'] + full_order_product_df['freight_value']\n",
    "\n",
    "# Example: Convert timestamp to datetime and extract useful parts\n",
    "full_order_product_df['order_purchase_timestamp'] = pd.to_datetime(full_order_product_df['order_purchase_timestamp'])\n",
    "full_order_product_df['purchase_weekday'] = full_order_product_df['order_purchase_timestamp'].dt.day_name()\n",
    "full_order_product_df['purchase_hour'] = full_order_product_df['order_purchase_timestamp'].dt.hour\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "88aeab4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order_id                            0\n",
      "customer_id                         0\n",
      "order_status                        0\n",
      "order_purchase_timestamp            0\n",
      "order_approved_at                 161\n",
      "order_delivered_carrier_date     1968\n",
      "order_delivered_customer_date    3229\n",
      "order_estimated_delivery_date       0\n",
      "order_item_id                     775\n",
      "product_id                        775\n",
      "seller_id                         775\n",
      "shipping_limit_date               775\n",
      "price                             775\n",
      "freight_value                     775\n",
      "product_category_name             775\n",
      "product_name_lenght               775\n",
      "product_description_lenght        775\n",
      "product_photos_qty                775\n",
      "product_weight_g                  775\n",
      "product_length_cm                 775\n",
      "product_height_cm                 775\n",
      "product_width_cm                  775\n",
      "total_value                       775\n",
      "purchase_weekday                    0\n",
      "purchase_hour                       0\n",
      "dtype: int64\n",
      "order_id                                 object\n",
      "customer_id                              object\n",
      "order_status                             object\n",
      "order_purchase_timestamp         datetime64[ns]\n",
      "order_approved_at                        object\n",
      "order_delivered_carrier_date             object\n",
      "order_delivered_customer_date            object\n",
      "order_estimated_delivery_date            object\n",
      "order_item_id                           float64\n",
      "product_id                               object\n",
      "seller_id                                object\n",
      "shipping_limit_date                      object\n",
      "price                                   float64\n",
      "freight_value                           float64\n",
      "product_category_name                    object\n",
      "product_name_lenght                     float64\n",
      "product_description_lenght              float64\n",
      "product_photos_qty                      float64\n",
      "product_weight_g                        float64\n",
      "product_length_cm                       float64\n",
      "product_height_cm                       float64\n",
      "product_width_cm                        float64\n",
      "total_value                             float64\n",
      "purchase_weekday                         object\n",
      "purchase_hour                             int32\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#after we create the new features we do the final check for missing values and data types\n",
    "# Check for missing values in the new dataframe\n",
    "print(full_order_product_df.isnull().sum())\n",
    "\n",
    "# Check data types\n",
    "print(full_order_product_df.dtypes)\n",
    "\n",
    "# Save the processed dataframe to a new CSV for easier access in the future\n",
    "full_order_product_df.to_csv('processed_data.csv', index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5664b620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing values\n",
    "# Dropping rows where order items are missing\n",
    "full_order_product_df.dropna(subset=['order_item_id'], inplace=True)\n",
    "\n",
    "# Filling missing dates with placeholder or imputation\n",
    "full_order_product_df['order_approved_at'].fillna(method='ffill', inplace=True)  # Example: forward fill\n",
    "\n",
    "# Converting date columns to datetime\n",
    "full_order_product_df['order_approved_at'] = pd.to_datetime(full_order_product_df['order_approved_at'])\n",
    "\n",
    "# Save the processed dataframe\n",
    "full_order_product_df.to_csv('processed_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "426a6690",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#create a simple recommendatuin system\n",
    "\n",
    "# Merging datasets to get the user, product, and category information together\n",
    "merged_df = pd.merge(orders_df, order_items_df, on='order_id')\n",
    "merged_df = pd.merge(merged_df, products_df, on='product_id')\n",
    "\n",
    "# Assuming each customer has a unique customer_id\n",
    "def recommend_products(customer_id, num_recommendations=5):\n",
    "    # Find products previously ordered by the customer\n",
    "    ordered_products = merged_df[merged_df['customer_id'] == customer_id]['product_category_name']\n",
    "    \n",
    "    # Recommend other products in the same categories\n",
    "    recommendations = merged_df[merged_df['product_category_name'].isin(ordered_products)]\n",
    "    return recommendations['product_id'].unique()[:num_recommendations]\n",
    "\n",
    "# Example usage\n",
    "#customer_id = 'some_customer_id'  # replace with an actual customer ID from the dataset\n",
    "#recommended_products = recommend_products(customer_id)\n",
    "#print(recommended_products)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca92ef1",
   "metadata": {},
   "source": [
    "\n",
    "### Collaborative Filtering\n",
    "\n",
    "Collaborative filtering is a method used in recommendation systems to predict the preferences of one user based on the preferences of other users. The basic assumption is that if a person A has the same opinion as a person B on an issue, A is more likely to have B's opinion on a different issue than that of a random person. There are two main types:\n",
    "\n",
    "1. **User-Based Collaborative Filtering**: This approach recommends items by finding similar users. For example, if user X and user Y both liked items A and B, and user X likes item C, the system might recommend item C to user Y. The similarity between users is usually calculated using methods like cosine similarity or Pearson correlation.\n",
    "\n",
    "2. **Item-Based Collaborative Filtering**: Instead of finding similar users, this approach finds similar items based on user ratings. For instance, if item A and item B are both highly rated by many users who rate both, and a user likes item A, the system might recommend item B to that user. Again, similarity can be measured by cosine similarity or other metrics.\n",
    "\n",
    "### Machine Learning Models in Recommendation Systems\n",
    "\n",
    "Machine learning models can be used in recommendation systems to predict user preferences and recommend items. These models can either be used independently or in conjunction with collaborative filtering. Common approaches include:\n",
    "\n",
    "1. **Classification Models**: These models can classify whether a user would like or dislike an item. Algorithms like logistic regression, decision trees, or support vector machines can be used.\n",
    "\n",
    "2. **Regression Models**: If the rating system is numerical, regression models can predict the rating a user might give to an item. Algorithms like linear regression or random forests can be used.\n",
    "\n",
    "3. **Matrix Factorization Techniques**: These are more advanced techniques used in recommendation systems, like Singular Value Decomposition (SVD). They work by decomposing the user-item interaction matrix into the product of two lower dimensionality rectangular matrices.\n",
    "\n",
    "4. **Neural Networks and Deep Learning**: Deep learning models can be used for more complex recommendation systems. They are particularly useful for handling large-scale and sparse datasets and can capture complex non-linear relationships between users and items.\n",
    "\n",
    "5. **Hybrid Models**: These models combine collaborative filtering with other machine learning techniques. For example, a hybrid model might use collaborative filtering to find a user's preferences and then a classification model to predict whether the user will like a new item.\n",
    "\n",
    "In practice, the choice of model depends on the specific requirements of the recommendation system, such as the size and nature of the dataset, the type of recommendations required (binary like/dislike, ratings, etc.), and the computational resources available. Each model has its strengths and weaknesses, and often a combination of these approaches yields the best results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536b9a55",
   "metadata": {},
   "source": [
    "#Step 3: Improvements and Machine Learning\n",
    "#Collaborative Filtering Techniques:\n",
    "\n",
    "#Collaborative filtering can be implemented in two main ways: user-based and item-based.\n",
    "#User-Based: Recommends items by finding similar users. This is often effective but can be computationally expensive.\n",
    "#Item-Based: Recommends items similar to those the user has liked before. It's generally faster and more stable than user-based."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6f66ab26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Merge Review Scores\n",
    "merged_df = pd.merge(full_order_product_df, reviews_df[['order_id', 'review_score']], on='order_id', how='left')\n",
    "\n",
    "# Step 2: Create 'Rating' Column\n",
    "# Handling missing values - fill with average score or a predefined score\n",
    "# You can also choose to fill with median or any other statistical measure\n",
    "default_rating = merged_df['review_score'].mean()\n",
    "merged_df['rating'] = merged_df['review_score'].fillna(default_rating)\n",
    "\n",
    "# Now, merged_df has a 'rating' column, which you can use for the collaborative filtering\n",
    "merged_df = pd.merge(full_order_product_df, reviews_df[['order_id', 'review_score']], on='order_id', how='left')\n",
    "\n",
    "# Step 4: Create the 'Rating' Column\n",
    "default_rating = merged_df['review_score'].mean()\n",
    "merged_df['rating'] = merged_df['review_score'].fillna(default_rating)\n",
    "\n",
    "#1. Reduce the Data Size\n",
    "\n",
    "# Example: Selecting top N products based on the number of orders\n",
    "top_products = merged_df['product_id'].value_counts().head(1000).index\n",
    "filtered_df = merged_df[merged_df['product_id'].isin(top_products)]\n",
    "\n",
    "#  create the pivot table with this filtered dataframe\n",
    "pivot_table = filtered_df.pivot_table(index='customer_id', columns='product_id', values='rating').fillna(0)\n",
    "\n",
    "#2. Use Sparse Matrix\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Create a sparse pivot table\n",
    "pivot_table_sparse = csr_matrix(pivot_table.fillna(0))\n",
    "\n",
    "#3. Check Data Types\n",
    "\n",
    "merged_df['customer_id'] = str(merged_df['customer_id'])\n",
    "merged_df['product_id'] = str(merged_df['product_id'])\n",
    "\n",
    "pivot_table = merged_df.pivot_table(index='customer_id', columns='product_id', values='rating').fillna(0)\n",
    "\n",
    "# Compute the cosine similarity\n",
    "item_similarity = cosine_similarity(pivot_table.T)\n",
    "item_similarity_df = pd.DataFrame(item_similarity, index=pivot_table.columns, columns=pivot_table.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "841f4df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Order Product DataFrame:\n",
      "                           order_id                       customer_id  \\\n",
      "0  e481f51cbdc54678b7cc49136f2d6af7  9ef432eb6251297304e76186b10a928d   \n",
      "1  53cdb2fc8bc7dce0b6741e2150273451  b0830fb4747a6c6d20dea0b8c802d7ef   \n",
      "2  47770eb9100c2d0c44946d9cf07ec65d  41ce2a54c0b03bf3443c3d931a367089   \n",
      "3  949d5b44dbf5de918fe9c16f97b45f8a  f88197465ea7920adcdbec7375364d82   \n",
      "4  ad21c59c0840e6cb83a9ceb5573f8159  8ab97904e6daea8866dbdbc4fb7aad2c   \n",
      "\n",
      "  order_status order_purchase_timestamp   order_approved_at  \\\n",
      "0    delivered      2017-10-02 10:56:33 2017-10-02 11:07:15   \n",
      "1    delivered      2018-07-24 20:41:37 2018-07-26 03:24:27   \n",
      "2    delivered      2018-08-08 08:38:49 2018-08-08 08:55:23   \n",
      "3    delivered      2017-11-18 19:28:06 2017-11-18 19:45:59   \n",
      "4    delivered      2018-02-13 21:18:39 2018-02-13 22:20:29   \n",
      "\n",
      "  order_delivered_carrier_date order_delivered_customer_date  \\\n",
      "0          2017-10-04 19:55:00           2017-10-10 21:25:13   \n",
      "1          2018-07-26 14:31:00           2018-08-07 15:27:45   \n",
      "2          2018-08-08 13:50:00           2018-08-17 18:06:29   \n",
      "3          2017-11-22 13:39:59           2017-12-02 00:28:42   \n",
      "4          2018-02-14 19:46:34           2018-02-16 18:17:02   \n",
      "\n",
      "  order_estimated_delivery_date  order_item_id  \\\n",
      "0           2017-10-18 00:00:00            1.0   \n",
      "1           2018-08-13 00:00:00            1.0   \n",
      "2           2018-09-04 00:00:00            1.0   \n",
      "3           2017-12-15 00:00:00            1.0   \n",
      "4           2018-02-26 00:00:00            1.0   \n",
      "\n",
      "                         product_id  ... product_name_lenght  \\\n",
      "0  87285b34884572647811a353c7ac498a  ...                40.0   \n",
      "1  595fac2a385ac33a80bd5114aec74eb8  ...                29.0   \n",
      "2  aa4383b373c6aca5d8797843e5594415  ...                46.0   \n",
      "3  d0b61bfb1de832b15ba9d266ca96e5b0  ...                59.0   \n",
      "4  65266b2da20d04dbe00c5c2d3bb7859e  ...                38.0   \n",
      "\n",
      "  product_description_lenght  product_photos_qty  product_weight_g  \\\n",
      "0                      268.0                 4.0             500.0   \n",
      "1                      178.0                 1.0             400.0   \n",
      "2                      232.0                 1.0             420.0   \n",
      "3                      468.0                 3.0             450.0   \n",
      "4                      316.0                 4.0             250.0   \n",
      "\n",
      "  product_length_cm  product_height_cm  product_width_cm  total_value  \\\n",
      "0              19.0                8.0              13.0        38.71   \n",
      "1              19.0               13.0              19.0       141.46   \n",
      "2              24.0               19.0              21.0       179.12   \n",
      "3              30.0               10.0              20.0        72.20   \n",
      "4              51.0               15.0              15.0        28.62   \n",
      "\n",
      "   purchase_weekday  purchase_hour  \n",
      "0            Monday             10  \n",
      "1           Tuesday             20  \n",
      "2         Wednesday              8  \n",
      "3          Saturday             19  \n",
      "4           Tuesday             21  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "\n",
      "Reviews DataFrame:\n",
      "                          review_id                          order_id  \\\n",
      "0  7bc2406110b926393aa56f80a40eba40  73fc7af87114b39712e6da79b0a377eb   \n",
      "1  80e641a11e56f04c1ad469d5645fdfde  a548910a1c6147796b98fdf73dbeba33   \n",
      "2  228ce5500dc1d8e020d8d1322874b6f0  f9e4b658b201a9f2ecdecbb34bed034b   \n",
      "3  e64fb393e7b32834bb789ff8bb30750e  658677c97b385a9be170737859d3511b   \n",
      "4  f7c4243c7fe1938f181bec41a392bdeb  8e6bfb81e283fa7e4f11123a3fb894f1   \n",
      "\n",
      "   review_score review_comment_title  \\\n",
      "0             4           No Comment   \n",
      "1             5           No Comment   \n",
      "2             5           No Comment   \n",
      "3             5           No Comment   \n",
      "4             5           No Comment   \n",
      "\n",
      "                              review_comment_message review_creation_date  \\\n",
      "0                                         No Comment  2018-01-18 00:00:00   \n",
      "1                                         No Comment  2018-03-10 00:00:00   \n",
      "2                                         No Comment  2018-02-17 00:00:00   \n",
      "3              Recebi bem antes do prazo estipulado.  2017-04-21 00:00:00   \n",
      "4  Parab√©ns lojas lannister adorei comprar pela I...  2018-03-01 00:00:00   \n",
      "\n",
      "  review_answer_timestamp  \n",
      "0     2018-01-18 21:46:59  \n",
      "1     2018-03-11 03:05:13  \n",
      "2     2018-02-18 14:36:24  \n",
      "3     2017-04-21 22:02:06  \n",
      "4     2018-03-02 10:26:53  \n",
      "\n",
      "Column 'order_id' in full_order_product_df: True\n",
      "Column 'order_id' in reviews_df: True\n",
      "\n",
      "Rating column added: True\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Examine the Dataframes\n",
    "print(\"Full Order Product DataFrame:\")\n",
    "print(full_order_product_df.head())\n",
    "\n",
    "print(\"\\nReviews DataFrame:\")\n",
    "print(reviews_df.head())\n",
    "\n",
    "# Step 2: Verify the 'order_id' column in both dataframes\n",
    "print(\"\\nColumn 'order_id' in full_order_product_df:\", 'order_id' in full_order_product_df.columns)\n",
    "print(\"Column 'order_id' in reviews_df:\", 'order_id' in reviews_df.columns)\n",
    "\n",
    "# Step 3: Re-attempt the Merge\n",
    "# Assuming the 'order_id' column exists in both dataframes and 'review_score' is in reviews_df\n",
    "merged_df = pd.merge(full_order_product_df, reviews_df[['order_id', 'review_score']], on='order_id', how='left')\n",
    "\n",
    "# Step 4: Create the 'Rating' Column\n",
    "default_rating = merged_df['review_score'].mean()\n",
    "merged_df['rating'] = merged_df['review_score'].fillna(default_rating)\n",
    "\n",
    "# Step 5: Check if 'rating' column is added\n",
    "print(\"\\nRating column added:\", 'rating' in merged_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "57440695",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Reduce the Data Size\n",
    "\n",
    "# Example: Selecting top N products based on the number of orders\n",
    "top_products = merged_df['product_id'].value_counts().head(1000).index\n",
    "filtered_df = merged_df[merged_df['product_id'].isin(top_products)]\n",
    "\n",
    "#  create the pivot table with this filtered dataframe\n",
    "pivot_table = filtered_df.pivot_table(index='customer_id', columns='product_id', values='rating').fillna(0)\n",
    "\n",
    "#2. Use Sparse Matrix\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Create a sparse pivot table\n",
    "pivot_table_sparse = csr_matrix(pivot_table.fillna(0))\n",
    "\n",
    "#3. Check Data Types\n",
    "\n",
    "merged_df['customer_id'] = str(merged_df['customer_id'])\n",
    "merged_df['product_id'] = str(merged_df['product_id'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order_id                                 object\n",
       "customer_id                              object\n",
       "order_status                             object\n",
       "order_purchase_timestamp         datetime64[ns]\n",
       "order_approved_at                datetime64[ns]\n",
       "order_delivered_carrier_date             object\n",
       "order_delivered_customer_date            object\n",
       "order_estimated_delivery_date            object\n",
       "order_item_id                           float64\n",
       "product_id                               object\n",
       "seller_id                                object\n",
       "shipping_limit_date                      object\n",
       "price                                   float64\n",
       "freight_value                           float64\n",
       "product_category_name                    object\n",
       "product_name_lenght                     float64\n",
       "product_description_lenght              float64\n",
       "product_photos_qty                      float64\n",
       "product_weight_g                        float64\n",
       "product_length_cm                       float64\n",
       "product_height_cm                       float64\n",
       "product_width_cm                        float64\n",
       "total_value                             float64\n",
       "purchase_weekday                         object\n",
       "purchase_hour                             int32\n",
       "review_score                            float64\n",
       "rating                                  float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901de243",
   "metadata": {},
   "source": [
    "Collaborative Filtering Techniques:\n",
    "\n",
    "Collaborative filtering can be implemented in two main ways: user-based and item-based.\n",
    "User-Based: Recommends items by finding similar users. This is often effective but can be computationally expensive.\n",
    "Item-Based: Recommends items similar to those the user has liked before. It's generally faster and more stable than user-based."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "396540cf",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "columns not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\atayc\\OneDrive\\Desktop\\M.Sc. 3. semester\\Computational Tools for Data Science\\brazil_ecommerce\\Recommender System\\RS.ipynb Cell 17\u001b[0m line \u001b[0;36m8\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/atayc/OneDrive/Desktop/M.Sc.%203.%20semester/Computational%20Tools%20for%20Data%20Science/brazil_ecommerce/Recommender%20System/RS.ipynb#X21sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# Compute the cosine similarity\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/atayc/OneDrive/Desktop/M.Sc.%203.%20semester/Computational%20Tools%20for%20Data%20Science/brazil_ecommerce/Recommender%20System/RS.ipynb#X21sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m item_similarity \u001b[39m=\u001b[39m cosine_similarity(pivot_table\u001b[39m.\u001b[39mT)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/atayc/OneDrive/Desktop/M.Sc.%203.%20semester/Computational%20Tools%20for%20Data%20Science/brazil_ecommerce/Recommender%20System/RS.ipynb#X21sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m item_similarity_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(item_similarity, index\u001b[39m=\u001b[39mpivot_table\u001b[39m.\u001b[39;49mcolumns, columns\u001b[39m=\u001b[39mpivot_table\u001b[39m.\u001b[39mcolumns)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/atayc/OneDrive/Desktop/M.Sc.%203.%20semester/Computational%20Tools%20for%20Data%20Science/brazil_ecommerce/Recommender%20System/RS.ipynb#X21sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# Function to make recommendations\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/atayc/OneDrive/Desktop/M.Sc.%203.%20semester/Computational%20Tools%20for%20Data%20Science/brazil_ecommerce/Recommender%20System/RS.ipynb#X21sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrecommend_products\u001b[39m(customer_id, n_items\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\atayc\\anaconda3\\lib\\site-packages\\scipy\\sparse\\_base.py:771\u001b[0m, in \u001b[0;36mspmatrix.__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    769\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgetnnz()\n\u001b[0;32m    770\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 771\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(attr \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m not found\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: columns not found"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "# Create the pivot table\n",
    "pivot_table = merged_df.pivot_table(index='customer_id', columns='product_id', values='rating').fillna(0)\n",
    "\n",
    "# Compute the cosine similarity\n",
    "item_similarity = cosine_similarity(pivot_table.T)\n",
    "item_similarity_df = pd.DataFrame(item_similarity, index=pivot_table.columns, columns=pivot_table.columns)\n",
    "\n",
    "# Function to make recommendations\n",
    "def recommend_products(customer_id, n_items=5):\n",
    "    if customer_id not in pivot_table.index:\n",
    "        raise ValueError(\"Customer ID not found in the data.\")\n",
    "    \n",
    "    customer_ratings = pivot_table.loc[customer_id]\n",
    "    similar_scores = item_similarity_df[customer_ratings.index].dot(customer_ratings.values)\n",
    "    similar_scores = similar_scores.sort_values(ascending=False)\n",
    "    return similar_scores.index[:n_items]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "702ca8dc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'merged_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Create a sparse matrix for customer-product interactions\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m customer_ids \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mfactorize(\u001b[43mmerged_df\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcustomer_id\u001b[39m\u001b[38;5;124m'\u001b[39m])[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      8\u001b[0m product_ids \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mfactorize(merged_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproduct_id\u001b[39m\u001b[38;5;124m'\u001b[39m])[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      9\u001b[0m ratings \u001b[38;5;241m=\u001b[39m merged_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrating\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n",
      "\u001b[1;31mNameError\u001b[0m: name 'merged_df' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.sparse import csr_matrix\n",
    "import numpy as np\n",
    "\n",
    "# Create a sparse matrix for customer-product interactions\n",
    "\n",
    "customer_ids = pd.factorize(merged_df['customer_id'])[0]\n",
    "product_ids = pd.factorize(merged_df['product_id'])[0]\n",
    "ratings = merged_df['rating'].values\n",
    "\n",
    "sparse_matrix = csr_matrix((ratings, (customer_ids, product_ids)), shape=(len(np.unique(customer_ids)), len(np.unique(product_ids))))\n",
    "\n",
    "# Compute cosine similarity between items\n",
    "item_similarity = cosine_similarity(sparse_matrix.T, dense_output=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ab111b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_id_mapping = pd.Series(index=np.unique(product_ids), data=merged_df['product_id'].unique())\n",
    "\n",
    "def recommend_products(product_id, top_n=5):\n",
    "    # Find the internal index of the product\n",
    "    product_idx = product_id_mapping[product_id_mapping == product_id].index[0]\n",
    "    \n",
    "    # Get similarity values\n",
    "    similarity_values = item_similarity[product_idx].toarray().flatten()\n",
    "    \n",
    "    # Get indices of top similar products\n",
    "    similar_product_indices = similarity_values.argsort()[::-1][1:top_n+1]  # Exclude the product itself\n",
    "    \n",
    "    # Convert these indices back to product IDs\n",
    "    similar_products = product_id_mapping.iloc[similar_product_indices].values\n",
    "\n",
    "    return similar_products\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32cd061",
   "metadata": {},
   "source": [
    "Now we will find an example product ID from our dataset :\n",
    "1.First we will take a look at a few entries in our merged_df dataframe to identify product IDs\n",
    "2.We will choose a product ID for testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d8780ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    87285b34884572647811a353c7ac498a\n",
      "1    595fac2a385ac33a80bd5114aec74eb8\n",
      "2    aa4383b373c6aca5d8797843e5594415\n",
      "3    d0b61bfb1de832b15ba9d266ca96e5b0\n",
      "4    65266b2da20d04dbe00c5c2d3bb7859e\n",
      "Name: product_id, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(merged_df['product_id'].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "bbd98cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['f23f6c4bbac2fbae03b381189d50296b' '3e4176d545618ed02f382a3057de32b4'\n",
      " '9cb854ba582f5a6b7832b86553c0b8ab' '65ae1951caecbb80c7d5e2e662ddb0dc'\n",
      " 'ee7cb55a3fb6c3f091ecbfcdc46359c6']\n"
     ]
    }
   ],
   "source": [
    "print(recommend_products('87285b34884572647811a353c7ac498a'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------\n",
    "------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged DataFrame:\n",
      "                           order_id  \\\n",
      "0  e481f51cbdc54678b7cc49136f2d6af7   \n",
      "1  53cdb2fc8bc7dce0b6741e2150273451   \n",
      "2  47770eb9100c2d0c44946d9cf07ec65d   \n",
      "3  949d5b44dbf5de918fe9c16f97b45f8a   \n",
      "4  ad21c59c0840e6cb83a9ceb5573f8159   \n",
      "\n",
      "                                         customer_id order_status  \\\n",
      "0  0         9ef432eb6251297304e76186b10a928d\\n1 ...    delivered   \n",
      "1  0         9ef432eb6251297304e76186b10a928d\\n1 ...    delivered   \n",
      "2  0         9ef432eb6251297304e76186b10a928d\\n1 ...    delivered   \n",
      "3  0         9ef432eb6251297304e76186b10a928d\\n1 ...    delivered   \n",
      "4  0         9ef432eb6251297304e76186b10a928d\\n1 ...    delivered   \n",
      "\n",
      "  order_purchase_timestamp   order_approved_at order_delivered_carrier_date  \\\n",
      "0      2017-10-02 10:56:33 2017-10-02 11:07:15          2017-10-04 19:55:00   \n",
      "1      2018-07-24 20:41:37 2018-07-26 03:24:27          2018-07-26 14:31:00   \n",
      "2      2018-08-08 08:38:49 2018-08-08 08:55:23          2018-08-08 13:50:00   \n",
      "3      2017-11-18 19:28:06 2017-11-18 19:45:59          2017-11-22 13:39:59   \n",
      "4      2018-02-13 21:18:39 2018-02-13 22:20:29          2018-02-14 19:46:34   \n",
      "\n",
      "  order_delivered_customer_date order_estimated_delivery_date  order_item_id  \\\n",
      "0           2017-10-10 21:25:13           2017-10-18 00:00:00            1.0   \n",
      "1           2018-08-07 15:27:45           2018-08-13 00:00:00            1.0   \n",
      "2           2018-08-17 18:06:29           2018-09-04 00:00:00            1.0   \n",
      "3           2017-12-02 00:28:42           2017-12-15 00:00:00            1.0   \n",
      "4           2018-02-16 18:17:02           2018-02-26 00:00:00            1.0   \n",
      "\n",
      "                                          product_id  ... product_photos_qty  \\\n",
      "0  0         87285b34884572647811a353c7ac498a\\n1 ...  ...                4.0   \n",
      "1  0         87285b34884572647811a353c7ac498a\\n1 ...  ...                1.0   \n",
      "2  0         87285b34884572647811a353c7ac498a\\n1 ...  ...                1.0   \n",
      "3  0         87285b34884572647811a353c7ac498a\\n1 ...  ...                3.0   \n",
      "4  0         87285b34884572647811a353c7ac498a\\n1 ...  ...                4.0   \n",
      "\n",
      "  product_weight_g  product_length_cm  product_height_cm product_width_cm  \\\n",
      "0            500.0               19.0                8.0             13.0   \n",
      "1            400.0               19.0               13.0             19.0   \n",
      "2            420.0               24.0               19.0             21.0   \n",
      "3            450.0               30.0               10.0             20.0   \n",
      "4            250.0               51.0               15.0             15.0   \n",
      "\n",
      "   total_value  purchase_weekday  purchase_hour  review_score  rating  \n",
      "0        38.71            Monday             10           4.0     4.0  \n",
      "1       141.46           Tuesday             20           4.0     4.0  \n",
      "2       179.12         Wednesday              8           5.0     5.0  \n",
      "3        72.20          Saturday             19           5.0     5.0  \n",
      "4        28.62           Tuesday             21           5.0     5.0  \n",
      "\n",
      "[5 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "# Merging datasets to get the user, product, and category information together\n",
    "merged_df = pd.merge(orders_df, order_items_df, on='order_id')\n",
    "merged_df = pd.merge(merged_df, products_df, on='product_id')\n",
    "\n",
    "# Step 1: Merge Review Scores\n",
    "merged_df = pd.merge(full_order_product_df, reviews_df[['order_id', 'review_score']], on='order_id', how='left')\n",
    "\n",
    "# Step 2: Create 'Rating' Column\n",
    "default_rating = merged_df['review_score'].mean()\n",
    "merged_df['rating'] = merged_df['review_score'].fillna(default_rating)\n",
    "\n",
    "merged_df['customer_id'] = str(merged_df['customer_id'])\n",
    "merged_df['product_id'] = str(merged_df['product_id'])\n",
    "\n",
    "\n",
    "# Print merged_df\n",
    "print(\"Merged DataFrame:\")\n",
    "print(merged_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Reduce Data Size\n",
    "top_products = merged_df['product_id'].value_counts().head(1000).index\n",
    "filtered_df = merged_df[merged_df['product_id'].isin(top_products)]\n",
    "\n",
    "# Step 4: Create Pivot Table\n",
    "pivot_table = filtered_df.pivot_table(index='customer_id', columns='product_id', values='rating').fillna(0)\n",
    "\n",
    "# Step 5: Use Sparse Matrix\n",
    "pivot_table_sparse = csr_matrix(pivot_table.fillna(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Compute Cosine Similarity\n",
    "#item_similarity = cosine_similarity(pivot_table_sparse.T, dense_output=False)\n",
    "#item_similarity_df = pd.DataFrame(item_similarity, index=pivot_table.columns, columns=pivot_table.columns)\n",
    "\n",
    "# Function to make recommendations\n",
    "def recommend_products(customer_id, n_items=5):\n",
    "    if customer_id not in pivot_table.index:\n",
    "        raise ValueError(\"Customer ID not found in the data.\")\n",
    "    \n",
    "    customer_ratings = pivot_table.loc[customer_id]\n",
    "    similar_scores = item_similarity_df[customer_ratings.index].dot(customer_ratings.values)\n",
    "    similar_scores = similar_scores.sort_values(ascending=False)\n",
    "    return similar_scores.index[:n_items]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sparse matrix for customer-product interactions\n",
    "customer_ids = pd.factorize(merged_df['customer_id'])[0]\n",
    "product_ids = pd.factorize(merged_df['product_id'])[0]\n",
    "ratings = merged_df['rating'].values\n",
    "sparse_matrix = csr_matrix((ratings, (customer_ids, product_ids)), shape=(len(np.unique(customer_ids)), len(np.unique(product_ids))))\n",
    "\n",
    "# Compute cosine similarity between items\n",
    "item_similarity_sparse = cosine_similarity(sparse_matrix.T, dense_output=False)\n",
    "\n",
    "# Map product indices to product IDs\n",
    "product_id_mapping = pd.Series(index=np.unique(product_ids), data=merged_df['product_id'].unique())\n",
    "\n",
    "# Function to recommend products based on similarity\n",
    "def recommend_products_sparse(product_id, top_n=5):\n",
    "    product_idx = product_id_mapping[product_id_mapping == product_id].index[0]\n",
    "    similarity_values = item_similarity_sparse[product_idx].toarray().flatten()\n",
    "    similar_product_indices = similarity_values.argsort()[::-1][1:top_n+1]\n",
    "    similar_products = product_id_mapping.iloc[similar_product_indices].values\n",
    "    return similar_products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0         9ef432eb6251297304e76186b10a928d\\n1 ...\n",
       "1    0         9ef432eb6251297304e76186b10a928d\\n1 ...\n",
       "2    0         9ef432eb6251297304e76186b10a928d\\n1 ...\n",
       "3    0         9ef432eb6251297304e76186b10a928d\\n1 ...\n",
       "4    0         9ef432eb6251297304e76186b10a928d\\n1 ...\n",
       "Name: customer_id, dtype: object"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df['customer_id'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Customer ID not found in the data.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\atayc\\OneDrive\\Desktop\\M.Sc. 3. semester\\Computational Tools for Data Science\\brazil_ecommerce\\Recommender System\\RS.ipynb Cell 30\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/atayc/OneDrive/Desktop/M.Sc.%203.%20semester/Computational%20Tools%20for%20Data%20Science/brazil_ecommerce/Recommender%20System/RS.ipynb#X42sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39m# Example usage:\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/atayc/OneDrive/Desktop/M.Sc.%203.%20semester/Computational%20Tools%20for%20Data%20Science/brazil_ecommerce/Recommender%20System/RS.ipynb#X42sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m customer_id_to_recommend \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m9ef432eb6251297304e76186b10a928d\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/atayc/OneDrive/Desktop/M.Sc.%203.%20semester/Computational%20Tools%20for%20Data%20Science/brazil_ecommerce/Recommender%20System/RS.ipynb#X42sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m collaborative_filtering_recommendations \u001b[39m=\u001b[39m collaborative_filtering_recommendation(customer_id_to_recommend)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/atayc/OneDrive/Desktop/M.Sc.%203.%20semester/Computational%20Tools%20for%20Data%20Science/brazil_ecommerce/Recommender%20System/RS.ipynb#X42sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mCollaborative Filtering Recommendations:\u001b[39m\u001b[39m\"\u001b[39m, collaborative_filtering_recommendations)\n",
      "\u001b[1;32mc:\\Users\\atayc\\OneDrive\\Desktop\\M.Sc. 3. semester\\Computational Tools for Data Science\\brazil_ecommerce\\Recommender System\\RS.ipynb Cell 30\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/atayc/OneDrive/Desktop/M.Sc.%203.%20semester/Computational%20Tools%20for%20Data%20Science/brazil_ecommerce/Recommender%20System/RS.ipynb#X42sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/atayc/OneDrive/Desktop/M.Sc.%203.%20semester/Computational%20Tools%20for%20Data%20Science/brazil_ecommerce/Recommender%20System/RS.ipynb#X42sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mRecommend products using collaborative filtering.\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/atayc/OneDrive/Desktop/M.Sc.%203.%20semester/Computational%20Tools%20for%20Data%20Science/brazil_ecommerce/Recommender%20System/RS.ipynb#X42sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/atayc/OneDrive/Desktop/M.Sc.%203.%20semester/Computational%20Tools%20for%20Data%20Science/brazil_ecommerce/Recommender%20System/RS.ipynb#X42sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m- recommended_products (list): List of recommended product IDs.\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/atayc/OneDrive/Desktop/M.Sc.%203.%20semester/Computational%20Tools%20for%20Data%20Science/brazil_ecommerce/Recommender%20System/RS.ipynb#X42sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/atayc/OneDrive/Desktop/M.Sc.%203.%20semester/Computational%20Tools%20for%20Data%20Science/brazil_ecommerce/Recommender%20System/RS.ipynb#X42sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mif\u001b[39;00m customer_id \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m pivot_table\u001b[39m.\u001b[39mindex:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/atayc/OneDrive/Desktop/M.Sc.%203.%20semester/Computational%20Tools%20for%20Data%20Science/brazil_ecommerce/Recommender%20System/RS.ipynb#X42sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCustomer ID not found in the data.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/atayc/OneDrive/Desktop/M.Sc.%203.%20semester/Computational%20Tools%20for%20Data%20Science/brazil_ecommerce/Recommender%20System/RS.ipynb#X42sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# Get the user's historical ratings\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/atayc/OneDrive/Desktop/M.Sc.%203.%20semester/Computational%20Tools%20for%20Data%20Science/brazil_ecommerce/Recommender%20System/RS.ipynb#X42sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m user_ratings \u001b[39m=\u001b[39m pivot_table\u001b[39m.\u001b[39mloc[customer_id]\n",
      "\u001b[1;31mValueError\u001b[0m: Customer ID not found in the data."
     ]
    }
   ],
   "source": [
    "def collaborative_filtering_recommendation(customer_id, n_items=5):\n",
    "    \"\"\"\n",
    "    Recommend products using collaborative filtering.\n",
    "\n",
    "    Parameters:\n",
    "    - customer_id (str): The ID of the customer for whom to make recommendations.\n",
    "    - n_items (int): Number of items to recommend.\n",
    "\n",
    "    Returns:\n",
    "    - recommended_products (list): List of recommended product IDs.\n",
    "    \"\"\"\n",
    "\n",
    "    if customer_id not in pivot_table.index:\n",
    "        raise ValueError(\"Customer ID not found in the data.\")\n",
    "\n",
    "    # Get the user's historical ratings\n",
    "    user_ratings = pivot_table.loc[customer_id]\n",
    "\n",
    "    # Find similar users based on user-item interactions\n",
    "    similar_users = pivot_table.dot(user_ratings)\n",
    "\n",
    "    # Exclude products the user has already interacted with\n",
    "    similar_users = similar_users.drop(user_ratings.index)\n",
    "\n",
    "    # Sort by similarity in descending order\n",
    "    similar_users = similar_users.sort_values(ascending=False)\n",
    "\n",
    "    # Get the top similar users and their ratings\n",
    "    top_similar_users = similar_users.head(n_items)\n",
    "\n",
    "    # Get the products these users have interacted with\n",
    "    recommended_products = pivot_table.loc[top_similar_users.index].mean().sort_values(ascending=False).index[:n_items]\n",
    "\n",
    "    return recommended_products\n",
    "\n",
    "# Example usage:\n",
    "customer_id_to_recommend = '9ef432eb6251297304e76186b10a928d'\n",
    "collaborative_filtering_recommendations = collaborative_filtering_recommendation(customer_id_to_recommend)\n",
    "print(\"Collaborative Filtering Recommendations:\", collaborative_filtering_recommendations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0         87285b34884572647811a353c7ac498a\\n1 ...\n",
      "1    0         87285b34884572647811a353c7ac498a\\n1 ...\n",
      "2    0         87285b34884572647811a353c7ac498a\\n1 ...\n",
      "3    0         87285b34884572647811a353c7ac498a\\n1 ...\n",
      "4    0         87285b34884572647811a353c7ac498a\\n1 ...\n",
      "Name: product_id, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(merged_df['product_id'].head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
