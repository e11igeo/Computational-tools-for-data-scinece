{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load and preprocess the data\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace file paths with the paths to the downloaded files\n",
    "orders_df = pd.read_csv(\"../datasets/olist_orders_dataset.csv\")\n",
    "order_items_df = pd.read_csv(\"../datasets/olist_order_items_dataset.csv\")\n",
    "products_df = pd.read_csv(\"../datasets/olist_products_dataset.csv\")\n",
    "reviews_df = pd.read_csv(\"../datasets/olist_order_reviews_dataset.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order_id                            0\n",
      "customer_id                         0\n",
      "order_status                        0\n",
      "order_purchase_timestamp            0\n",
      "order_approved_at                 160\n",
      "order_delivered_carrier_date     1783\n",
      "order_delivered_customer_date    2965\n",
      "order_estimated_delivery_date       0\n",
      "dtype: int64\n",
      "order_id               0\n",
      "order_item_id          0\n",
      "product_id             0\n",
      "seller_id              0\n",
      "shipping_limit_date    0\n",
      "price                  0\n",
      "freight_value          0\n",
      "dtype: int64\n",
      "product_id                      0\n",
      "product_category_name         610\n",
      "product_name_lenght           610\n",
      "product_description_lenght    610\n",
      "product_photos_qty            610\n",
      "product_weight_g                2\n",
      "product_length_cm               2\n",
      "product_height_cm               2\n",
      "product_width_cm                2\n",
      "dtype: int64\n",
      "review_id                      0\n",
      "order_id                       0\n",
      "review_score                   0\n",
      "review_comment_title       87656\n",
      "review_comment_message     58247\n",
      "review_creation_date           0\n",
      "review_answer_timestamp        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#checking for missing values \n",
    "print(orders_df.isnull().sum())\n",
    "print(order_items_df.isnull().sum())\n",
    "print(products_df.isnull().sum())\n",
    "print(reviews_df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute categorical data with the mode (most frequent category)\n",
    "products_df['product_category_name'].fillna(products_df['product_category_name'].mode()[0], inplace=True)\n",
    "\n",
    "# Impute numerical data with the mean\n",
    "for col in ['product_name_lenght', 'product_description_lenght', 'product_photos_qty']:\n",
    "    products_df[col].fillna(products_df[col].mean(), inplace=True)\n",
    "\n",
    "# For very few missing values in product dimensions and weight, use mean\n",
    "for col in ['product_weight_g', 'product_length_cm', 'product_height_cm', 'product_width_cm']:\n",
    "    products_df[col].fillna(products_df[col].mean(), inplace=True)\n",
    "\n",
    "# For review comments, replace missing values with 'No Comment'\n",
    "reviews_df['review_comment_title'].fillna('No Comment', inplace=True)\n",
    "reviews_df['review_comment_message'].fillna('No Comment', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in Product Dataset:\n",
      "product_id                    0\n",
      "product_category_name         0\n",
      "product_name_lenght           0\n",
      "product_description_lenght    0\n",
      "product_photos_qty            0\n",
      "product_weight_g              0\n",
      "product_length_cm             0\n",
      "product_height_cm             0\n",
      "product_width_cm              0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in Review Dataset:\n",
      "review_id                  0\n",
      "order_id                   0\n",
      "review_score               0\n",
      "review_comment_title       0\n",
      "review_comment_message     0\n",
      "review_creation_date       0\n",
      "review_answer_timestamp    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#after handling the missing values we recheck the datasets to ensure that all missing values have been appropriately addressed\n",
    "print(\"Missing values in Product Dataset:\")\n",
    "print(products_df.isnull().sum())\n",
    "\n",
    "print(\"\\nMissing values in Review Dataset:\")\n",
    "print(reviews_df.isnull().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging the datasets\n",
    "\n",
    "full_order_df = pd.merge(orders_df, order_items_df, on='order_id', how='left')\n",
    "full_order_product_df = pd.merge(full_order_df, products_df, on='product_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating new features \n",
    "#based on the merged data, we want to create new features that can help in our analysis or model building\n",
    "\n",
    "full_order_product_df['total_value'] = full_order_product_df['price'] + full_order_product_df['freight_value']\n",
    "\n",
    "# Example: Convert timestamp to datetime and extract useful parts\n",
    "full_order_product_df['order_purchase_timestamp'] = pd.to_datetime(full_order_product_df['order_purchase_timestamp'])\n",
    "full_order_product_df['purchase_weekday'] = full_order_product_df['order_purchase_timestamp'].dt.day_name()\n",
    "full_order_product_df['purchase_hour'] = full_order_product_df['order_purchase_timestamp'].dt.hour\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order_id                            0\n",
      "customer_id                         0\n",
      "order_status                        0\n",
      "order_purchase_timestamp            0\n",
      "order_approved_at                 161\n",
      "order_delivered_carrier_date     1968\n",
      "order_delivered_customer_date    3229\n",
      "order_estimated_delivery_date       0\n",
      "order_item_id                     775\n",
      "product_id                        775\n",
      "seller_id                         775\n",
      "shipping_limit_date               775\n",
      "price                             775\n",
      "freight_value                     775\n",
      "product_category_name             775\n",
      "product_name_lenght               775\n",
      "product_description_lenght        775\n",
      "product_photos_qty                775\n",
      "product_weight_g                  775\n",
      "product_length_cm                 775\n",
      "product_height_cm                 775\n",
      "product_width_cm                  775\n",
      "total_value                       775\n",
      "purchase_weekday                    0\n",
      "purchase_hour                       0\n",
      "dtype: int64\n",
      "order_id                                 object\n",
      "customer_id                              object\n",
      "order_status                             object\n",
      "order_purchase_timestamp         datetime64[ns]\n",
      "order_approved_at                        object\n",
      "order_delivered_carrier_date             object\n",
      "order_delivered_customer_date            object\n",
      "order_estimated_delivery_date            object\n",
      "order_item_id                           float64\n",
      "product_id                               object\n",
      "seller_id                                object\n",
      "shipping_limit_date                      object\n",
      "price                                   float64\n",
      "freight_value                           float64\n",
      "product_category_name                    object\n",
      "product_name_lenght                     float64\n",
      "product_description_lenght              float64\n",
      "product_photos_qty                      float64\n",
      "product_weight_g                        float64\n",
      "product_length_cm                       float64\n",
      "product_height_cm                       float64\n",
      "product_width_cm                        float64\n",
      "total_value                             float64\n",
      "purchase_weekday                         object\n",
      "purchase_hour                             int32\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#after we create the new features we do the final check for missing values and data types\n",
    "# Check for missing values in the new dataframe\n",
    "print(full_order_product_df.isnull().sum())\n",
    "\n",
    "# Check data types\n",
    "print(full_order_product_df.dtypes)\n",
    "\n",
    "# Save the processed dataframe to a new CSV for easier access in the future\n",
    "full_order_product_df.to_csv('processed_data.csv', index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing values\n",
    "# Dropping rows where order items are missing\n",
    "full_order_product_df.dropna(subset=['order_item_id'], inplace=True)\n",
    "\n",
    "# Filling missing dates with placeholder or imputation\n",
    "full_order_product_df['order_approved_at'].fillna(method='ffill', inplace=True)  # Example: forward fill\n",
    "\n",
    "# Converting date columns to datetime\n",
    "full_order_product_df['order_approved_at'] = pd.to_datetime(full_order_product_df['order_approved_at'])\n",
    "\n",
    "# Save the processed dataframe\n",
    "full_order_product_df.to_csv('processed_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A simple recommender system based on previously ordered product categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging datasets to get the user, product, and category information together\n",
    "merged_df = pd.merge(orders_df, order_items_df, on='order_id')\n",
    "merged_df = pd.merge(merged_df, products_df, on='product_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_products(customer_id, num_recommendations=5):\n",
    "    # Find products previously ordered by the customer\n",
    "    ordered_products = merged_df[merged_df['customer_id'] == customer_id]['product_category_name']\n",
    "    \n",
    "    # Recommend other products in the same categories\n",
    "    recommendations = merged_df[merged_df['product_category_name'].isin(ordered_products)]\n",
    "    return recommendations['product_id'].unique()[:num_recommendations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['87285b34884572647811a353c7ac498a',\n",
       "       'be021417a6acb56b9b50d3fd2714baa8',\n",
       "       'a5a0e71a81ae65aa335e71c06261e260',\n",
       "       '97f1396a5a1f7c07ba51784efdec44b8',\n",
       "       '978859c6048ded0fa8bf3b9ea8236387'], dtype=object)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend_products(merged_df['customer_id'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recommendations based on Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge Review Scores\n",
    "merged_df = pd.merge(full_order_product_df, reviews_df[['order_id', 'review_score']], on='order_id', how='left')\n",
    "\n",
    "# Create 'Rating' Column\n",
    "# Handling missing values - fill with average score or a predefined score\n",
    "default_rating = merged_df['review_score'].mean()\n",
    "merged_df['rating'] = merged_df['review_score'].fillna(default_rating)\n",
    "\n",
    "merged_df = pd.merge(full_order_product_df, reviews_df[['order_id', 'review_score']], on='order_id', how='left')\n",
    "\n",
    "# Step 4: Create the 'Rating' Column\n",
    "default_rating = merged_df['review_score'].mean()\n",
    "merged_df['rating'] = merged_df['review_score'].fillna(default_rating)\n",
    "\n",
    "# Selecting top N products based on the number of orders\n",
    "top_products = merged_df['product_id'].value_counts().head(2000).index\n",
    "filtered_df = merged_df[merged_df['product_id'].isin(top_products)]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  create the pivot table with this filtered dataframe\n",
    "pivot_table = filtered_df.pivot_table(index='customer_id', columns='product_id', values='rating').fillna(0)\n",
    "pivot_table_sparse = csr_matrix(pivot_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute cosine similarity between items\n",
    "item_similarity = cosine_similarity(pivot_table_sparse.T, dense_output=False)\n",
    "\n",
    "# Create a mapping from product IDs to internal indices\n",
    "unique_product_ids = filtered_df['product_id'].unique()\n",
    "product_id_mapping = pd.Series(index=unique_product_ids, data=range(len(unique_product_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_products_cosine(product_id, top_n=5):\n",
    "    if product_id not in product_id_mapping.index:\n",
    "        raise ValueError(f\"Product ID '{product_id}' not found in the mapping.\")\n",
    "    \n",
    "    # Find the internal index of the product\n",
    "    product_idx = product_id_mapping[product_id_mapping.index == product_id].iloc[0]\n",
    "    \n",
    "    print(\"Product ID:\", product_id)\n",
    "    print(\"Internal Index:\", product_idx)\n",
    "    \n",
    "    # Get similarity values\n",
    "    similarity_values = item_similarity[product_idx].toarray().flatten()\n",
    "    \n",
    "    # Get indices of top similar products\n",
    "    similar_product_indices = similarity_values.argsort()[::-1][1:top_n+1]  # Exclude the product itself\n",
    "    \n",
    "    # Convert these indices back to product IDs\n",
    "    similar_products = product_id_mapping.iloc[similar_product_indices].index\n",
    "    \n",
    "    return similar_products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product ID: cc5447118c174dcc6456c84ccb29e6f7\n",
      "Internal Index: 104\n"
     ]
    }
   ],
   "source": [
    "random_product_id = filtered_df['product_id'].sample().iloc[0]\n",
    "recommendations = recommend_products_cosine(random_product_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recommendations based on Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sparse matrix for customer-product interactions\n",
    "customer_ids = pd.factorize(filtered_df['customer_id'])[0]\n",
    "product_ids = pd.factorize(filtered_df['product_id'])[0]\n",
    "ratings = filtered_df['rating'].values\n",
    "\n",
    "pivot_table_sparse = csr_matrix((ratings, (customer_ids, product_ids)), shape=(len(np.unique(customer_ids)), len(np.unique(product_ids))))\n",
    "\n",
    "# Create a mapping from customer and product IDs to internal indices\n",
    "customer_id_mapping = pd.Series(index=filtered_df['customer_id'].unique(), data=np.unique(customer_ids))\n",
    "product_id_mapping = pd.Series(index=filtered_df['product_id'].unique(), data=np.unique(product_ids))\n",
    "\n",
    "# Compute cosine similarity between items\n",
    "item_similarity = cosine_similarity(pivot_table_sparse.T, dense_output=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_products_collaborative(customer_id, top_n=5):\n",
    "    if customer_id not in customer_id_mapping.index:\n",
    "        raise ValueError(f\"Customer ID '{customer_id}' not found in the mapping.\")\n",
    "\n",
    "    # Find the internal index of the customer\n",
    "    customer_idx = customer_id_mapping[customer_id]\n",
    "\n",
    "    # Get ratings for the customer\n",
    "    customer_ratings = pivot_table_sparse[customer_idx].reshape(1, -1)\n",
    "\n",
    "    print(\"Dimensions of item_similarity:\", item_similarity.shape)\n",
    "    print(\"Dimensions of customer_ratings:\", customer_ratings.shape)\n",
    "\n",
    "    # Compute the weighted sum of similarity values\n",
    "    weighted_sum = item_similarity.dot(customer_ratings.T)\n",
    "\n",
    "    # Get indices of purchased products\n",
    "    purchased_product_indices = product_ids[customer_ratings.nonzero()[1]]\n",
    "\n",
    "    # Set the corresponding values in the weighted_sum to 0\n",
    "    weighted_sum[purchased_product_indices] = 0\n",
    "    print(weighted_sum)\n",
    "    print('--------')\n",
    "    print(top_n)\n",
    "\n",
    "    top_n = min(top_n, weighted_sum.shape[0])\n",
    "    kth = min(top_n, weighted_sum.shape[0]) - 1\n",
    "    kth = max(0, kth)  # Ensure kth is not negative\n",
    "    \n",
    "    if kth < len(weighted_sum.data):\n",
    "        top_product_indices = np.argpartition(weighted_sum.data, kth)[:kth + 1]\n",
    "        top_products = product_id_mapping.iloc[weighted_sum.indices[top_product_indices]].index\n",
    "    else:\n",
    "        # Handle the case when kth is out of bounds\n",
    "        top_products = product_id_mapping.index\n",
    "    \n",
    "    return top_products[:top_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of item_similarity: (2000, 2000)\n",
      "Dimensions of customer_ratings: (1, 2000)\n",
      "  (287, 0)\t0.6114938481177251\n",
      "  (405, 0)\t0.0\n",
      "  (603, 0)\t9.999999999999996\n",
      "  (1624, 0)\t0.016274346579488577\n",
      "  (1951, 0)\t0.11210013037294261\n",
      "--------\n",
      "5\n",
      "Collaborative Filtering Recommendations: Index(['595fac2a385ac33a80bd5114aec74eb8', '595fac2a385ac33a80bd5114aec74eb8',\n",
      "       '595fac2a385ac33a80bd5114aec74eb8', '595fac2a385ac33a80bd5114aec74eb8',\n",
      "       '595fac2a385ac33a80bd5114aec74eb8'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "random_customer_id = filtered_df['customer_id'].sample().iloc[0]\n",
    "recommendations_collaborative = recommend_products_collaborative(random_customer_id)\n",
    "print(\"Collaborative Filtering Recommendations:\", recommendations_collaborative)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
