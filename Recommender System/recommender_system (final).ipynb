{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load and preprocess the data\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace file paths with the paths to the downloaded files\n",
    "orders_df = pd.read_csv(\"C:/Users/lydi_/OneDrive/Documents/DTU master , lectures and exercises/Computational Tools for Data Science/olist_orders_dataset.csv\")\n",
    "order_items_df = pd.read_csv(\"C:/Users/lydi_/OneDrive/Documents/DTU master , lectures and exercises/Computational Tools for Data Science/olist_order_items_dataset.csv\")\n",
    "products_df = pd.read_csv(\"C:/Users/lydi_/OneDrive/Documents/DTU master , lectures and exercises/Computational Tools for Data Science/olist_products_dataset.csv\")\n",
    "reviews_df = pd.read_csv(\"C:/Users/lydi_/OneDrive/Documents/DTU master , lectures and exercises/Computational Tools for Data Science/olist_order_reviews_dataset.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order_id                            0\n",
      "customer_id                         0\n",
      "order_status                        0\n",
      "order_purchase_timestamp            0\n",
      "order_approved_at                 160\n",
      "order_delivered_carrier_date     1783\n",
      "order_delivered_customer_date    2965\n",
      "order_estimated_delivery_date       0\n",
      "dtype: int64\n",
      "order_id               0\n",
      "order_item_id          0\n",
      "product_id             0\n",
      "seller_id              0\n",
      "shipping_limit_date    0\n",
      "price                  0\n",
      "freight_value          0\n",
      "dtype: int64\n",
      "product_id                      0\n",
      "product_category_name         610\n",
      "product_name_lenght           610\n",
      "product_description_lenght    610\n",
      "product_photos_qty            610\n",
      "product_weight_g                2\n",
      "product_length_cm               2\n",
      "product_height_cm               2\n",
      "product_width_cm                2\n",
      "dtype: int64\n",
      "review_id                      0\n",
      "order_id                       0\n",
      "review_score                   0\n",
      "review_comment_title       87656\n",
      "review_comment_message     58247\n",
      "review_creation_date           0\n",
      "review_answer_timestamp        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Checking for missing values in each DataFrame\n",
    "print(orders_df.isnull().sum())\n",
    "print(order_items_df.isnull().sum())\n",
    "print(products_df.isnull().sum())\n",
    "print(reviews_df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputing missing values in 'product_category_name' with the most frequent category (mode)\n",
    "products_df['product_category_name'].fillna(products_df['product_category_name'].mode()[0], inplace=True)\n",
    "\n",
    "# Imputing missing numerical data in product details with their respective mean values\n",
    "for col in ['product_name_lenght', 'product_description_lenght', 'product_photos_qty']:\n",
    "    products_df[col].fillna(products_df[col].mean(), inplace=True)\n",
    "\n",
    "# Imputing missing values in product dimensions and weight with mean\n",
    "\n",
    "for col in ['product_weight_g', 'product_length_cm', 'product_height_cm', 'product_width_cm']:\n",
    "    products_df[col].fillna(products_df[col].mean(), inplace=True)\n",
    "\n",
    "# Replacing missing values in review comments with a placeholder 'No Comment'\n",
    "reviews_df['review_comment_title'].fillna('No Comment', inplace=True)\n",
    "reviews_df['review_comment_message'].fillna('No Comment', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in Product Dataset:\n",
      "product_id                    0\n",
      "product_category_name         0\n",
      "product_name_lenght           0\n",
      "product_description_lenght    0\n",
      "product_photos_qty            0\n",
      "product_weight_g              0\n",
      "product_length_cm             0\n",
      "product_height_cm             0\n",
      "product_width_cm              0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in Review Dataset:\n",
      "review_id                  0\n",
      "order_id                   0\n",
      "review_score               0\n",
      "review_comment_title       0\n",
      "review_comment_message     0\n",
      "review_creation_date       0\n",
      "review_answer_timestamp    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Rechecking for missing values in Product and Review DataSets after imputation\n",
    "print(\"Missing values in Product Dataset:\")\n",
    "print(products_df.isnull().sum())\n",
    "\n",
    "print(\"\\nMissing values in Review Dataset:\")\n",
    "print(reviews_df.isnull().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging the orders, items, and products datasets into a single DataFrame\n",
    "\n",
    "full_order_df = pd.merge(orders_df, order_items_df, on='order_id', how='left')\n",
    "full_order_product_df = pd.merge(full_order_df, products_df, on='product_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating new feature 'total_value' by adding price and freight value\n",
    "#based on the merged data, we want to create new features that can help in our analysis or model building\n",
    "full_order_product_df['total_value'] = full_order_product_df['price'] + full_order_product_df['freight_value']\n",
    "\n",
    "# Converting 'order_purchase_timestamp' from string to datetime and extracting weekday and hour\n",
    "full_order_product_df['order_purchase_timestamp'] = pd.to_datetime(full_order_product_df['order_purchase_timestamp'])\n",
    "full_order_product_df['purchase_weekday'] = full_order_product_df['order_purchase_timestamp'].dt.day_name()\n",
    "full_order_product_df['purchase_hour'] = full_order_product_df['order_purchase_timestamp'].dt.hour\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order_id                            0\n",
      "customer_id                         0\n",
      "order_status                        0\n",
      "order_purchase_timestamp            0\n",
      "order_approved_at                 161\n",
      "order_delivered_carrier_date     1968\n",
      "order_delivered_customer_date    3229\n",
      "order_estimated_delivery_date       0\n",
      "order_item_id                     775\n",
      "product_id                        775\n",
      "seller_id                         775\n",
      "shipping_limit_date               775\n",
      "price                             775\n",
      "freight_value                     775\n",
      "product_category_name             775\n",
      "product_name_lenght               775\n",
      "product_description_lenght        775\n",
      "product_photos_qty                775\n",
      "product_weight_g                  775\n",
      "product_length_cm                 775\n",
      "product_height_cm                 775\n",
      "product_width_cm                  775\n",
      "total_value                       775\n",
      "purchase_weekday                    0\n",
      "purchase_hour                       0\n",
      "dtype: int64\n",
      "order_id                                 object\n",
      "customer_id                              object\n",
      "order_status                             object\n",
      "order_purchase_timestamp         datetime64[ns]\n",
      "order_approved_at                        object\n",
      "order_delivered_carrier_date             object\n",
      "order_delivered_customer_date            object\n",
      "order_estimated_delivery_date            object\n",
      "order_item_id                           float64\n",
      "product_id                               object\n",
      "seller_id                                object\n",
      "shipping_limit_date                      object\n",
      "price                                   float64\n",
      "freight_value                           float64\n",
      "product_category_name                    object\n",
      "product_name_lenght                     float64\n",
      "product_description_lenght              float64\n",
      "product_photos_qty                      float64\n",
      "product_weight_g                        float64\n",
      "product_length_cm                       float64\n",
      "product_height_cm                       float64\n",
      "product_width_cm                        float64\n",
      "total_value                             float64\n",
      "purchase_weekday                         object\n",
      "purchase_hour                             int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#after we create the new features we do the final check for missing values and data types\n",
    "# Checking for missing values and verifying data types in the merged DataFrame\n",
    "print(full_order_product_df.isnull().sum())\n",
    "\n",
    "# Check data types\n",
    "print(full_order_product_df.dtypes)\n",
    "\n",
    "# Saving the processed DataFrame to a CSV file for future usee\n",
    "full_order_product_df.to_csv('processed_data.csv', index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing values\n",
    "# Dropping rows where order items are missing\n",
    "full_order_product_df.dropna(subset=['order_item_id'], inplace=True)\n",
    "\n",
    "# Filling missing dates with placeholder or imputation\n",
    "full_order_product_df['order_approved_at'].fillna(method='ffill', inplace=True)  # Example: forward fill\n",
    "\n",
    "# Converting date columns to datetime\n",
    "full_order_product_df['order_approved_at'] = pd.to_datetime(full_order_product_df['order_approved_at'])\n",
    "\n",
    "# Save the processed dataframe\n",
    "full_order_product_df.to_csv('processed_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A simple recommender system based on previously ordered product categories\n",
    "\n",
    "This code defines a simple recommender system that suggests new products to a customer based on the categories of products they have previously ordered. It uses the merged dataset to find the categories of products a specific customer has ordered and then recommends different products from these same categories. The function recommend_products can be used to get a list of recommendations for any customer in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging datasets to get the user, product, and category information together\n",
    "merged_df = pd.merge(orders_df, order_items_df, on='order_id')\n",
    "merged_df = pd.merge(merged_df, products_df, on='product_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_products(customer_id, num_recommendations=5):       \n",
    "     # This function recommends products to a customer based on their previous orders.\n",
    "\n",
    "     # Find products previously ordered by the customer by filtering the merged DataFrame.\n",
    "     # It selects the 'product_category_name' for orders where 'customer_id' matches the given customer_id.\n",
    "    \n",
    "     # Find products previously ordered by the customer\n",
    "    ordered_products = merged_df[merged_df['customer_id'] == customer_id]['product_category_name']\n",
    "    # Recommend other products in the same categories.\n",
    "    # This is done by selecting entries from the merged DataFrame where 'product_category_name' is one of the categories in 'ordered_products'.\n",
    "    # It then selects the 'product_id' of these products.\n",
    "    \n",
    "    \n",
    "    # Returning the unique product IDs of the recommendations, limited to the number specified by 'num_recommendations'.\n",
    "    recommendations = merged_df[merged_df['product_category_name'].isin(ordered_products)]\n",
    "    return recommendations['product_id'].unique()[:num_recommendations]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This output represents the recommendation system's suggestions for a customer based on their previous purchase history. Specifically, it recommends products that are in the same categories as those previously ordered by the customer.\n",
    "\n",
    "So, when we call recommend_products(merged_df['customer_id'][0]), it's returning the top 5 recommended product IDs for the first customer in your merged dataset, based on the categories of products they have bought before. We can do it for other customers also , not only for the first one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['595fac2a385ac33a80bd5114aec74eb8',\n",
       "       '72a97c271b2e429974398f46b93ae530',\n",
       "       '009c09f439988bc06a93d6b8186dce73',\n",
       "       '00baba5b58e274d0332a0c8a0a66f877',\n",
       "       'c6c1f263e076bd9c1f1640250a5d0c29'], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example usage of the function: recommend products to the first customer in the merged dataset.\n",
    "recommend_products(merged_df['customer_id'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recommendations based on Cosine Similarity  \n",
    "\n",
    "This code creates a recommendation system based on item similarity using cosine similarity. It first processes the data to create a user-item rating matrix, computes the item similarity matrix, and then defines a function to recommend similar products for a given product ID. The function selects the top N similar products based on their cosine similarity scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge Review Scores with the full order product dataframe\n",
    "merged_df = pd.merge(full_order_product_df, reviews_df[['order_id', 'review_score']], on='order_id', how='left')\n",
    "\n",
    "# Create a 'rating' column in merged_df. Missing review scores are filled with the average score\n",
    "# Handling missing values - fill with average score or a predefined score\n",
    "default_rating = merged_df['review_score'].mean()\n",
    "merged_df['rating'] = merged_df['review_score'].fillna(default_rating)\n",
    "\n",
    "\n",
    "# This line seems redundant as the merge operation and rating creation are repeated from the previous steps\n",
    "merged_df = pd.merge(full_order_product_df, reviews_df[['order_id', 'review_score']], on='order_id', how='left')\n",
    "\n",
    "# Repeating the creation of the 'rating' column with missing values filled with the average review score\n",
    "default_rating = merged_df['review_score'].mean()\n",
    "merged_df['rating'] = merged_df['review_score'].fillna(default_rating)\n",
    "\n",
    "# Selecting the top 2000 products based on the number of orders\n",
    "top_products = merged_df['product_id'].value_counts().head(2000).index\n",
    "filtered_df = merged_df[merged_df['product_id'].isin(top_products)]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a pivot table with 'customer_id' as rows, 'product_id' as columns, and 'rating' as values, filling missing values with 0\n",
    "pivot_table = filtered_df.pivot_table(index='customer_id', columns='product_id', values='rating').fillna(0)\n",
    "pivot_table_sparse = csr_matrix(pivot_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing cosine similarity between items using the sparse matrix of the pivot table\n",
    "item_similarity = cosine_similarity(pivot_table_sparse.T, dense_output=False)\n",
    "\n",
    "# Creating a mapping from product IDs to internal indices used in the similarity matrix\n",
    "unique_product_ids = filtered_df['product_id'].unique()\n",
    "product_id_mapping = pd.Series(index=unique_product_ids, data=range(len(unique_product_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_products_cosine(product_id, top_n=5):\n",
    "    # Function to recommend products based on cosine similarity\n",
    "\n",
    "    # Check if the product ID exists in the mapping, raise an error if not found\n",
    "    if product_id not in product_id_mapping.index:\n",
    "        raise ValueError(f\"Product ID '{product_id}' not found in the mapping.\")\n",
    "    \n",
    "    # Find the internal index of the product in the similarity matrix\n",
    "    product_idx = product_id_mapping[product_id_mapping.index == product_id].iloc[0]\n",
    "    \n",
    "    print(\"Product ID:\", product_id)\n",
    "    print(\"Internal Index:\", product_idx)\n",
    "    \n",
    "    # Get similarity values for the product\n",
    "    similarity_values = item_similarity[product_idx].toarray().flatten()\n",
    "    \n",
    "    # Get indices of top similar products, excluding the product itself\n",
    "    similar_product_indices = similarity_values.argsort()[::-1][1:top_n+1]  # Exclude the product itself\n",
    "    \n",
    "    # Convert these indices back to product IDs\n",
    "    similar_products = product_id_mapping.iloc[similar_product_indices].index\n",
    "    \n",
    "    return similar_products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We call the function with the randomly selected product ID. This function is designed to find products similar to given product_ID.\n",
    "\n",
    "In the outpu the product_ID selected randomly for which recommendations are being generated. It's a unique identifier for a product in our dataset. The function then uses this internal indec to find the cosine similarity scores of this product with all other products. It sorts these scores to find the top 'N' similar products, which are then returned as recommendations.\n",
    "\n",
    "The recommendations variable will hold the product ID of the top N similar products. These are the products most similar to the randomly chocen one, as determined by the cosine similarity in their features (in this case, based on customer ratings). \n",
    "\n",
    "\n",
    "This output is part of the testing process to ensure that your recommendation system is functioning as expected. By using a random product Id , we can simulate how can the system would operate in a real-world scenario, recommending products similar to any given product. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product ID: 810e2944bca9850b934e1570ba372e7d\n",
      "Internal Index: 1318\n"
     ]
    }
   ],
   "source": [
    "# Testing the function with a random product ID from the filtered dataset\n",
    "random_product_id = filtered_df['product_id'].sample().iloc[0]\n",
    "recommendations = recommend_products_cosine(random_product_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recommendations based on Collaborative Filtering\n",
    "\n",
    "This code implements a collaborative filtering recommendation system. It first creates a sparse matrix to represent customer-product interactions and computes item similarity based on these interactions. The recommend_products_collaborative function then recommends products for a given customer ID based on these interactions and similarity scores, excluding products that the customer has already purchased. The test case at the end demonstrates how the function can be used to generate recommendations for a random customer from your dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sparse matrix for customer-product interactions\n",
    "customer_ids = pd.factorize(filtered_df['customer_id'])[0]\n",
    "product_ids = pd.factorize(filtered_df['product_id'])[0]\n",
    "ratings = filtered_df['rating'].values\n",
    "\n",
    "\n",
    "# Creating a sparse matrix with customers as rows, products as columns, and ratings as values\n",
    "pivot_table_sparse = csr_matrix((ratings, (customer_ids, product_ids)), shape=(len(np.unique(customer_ids)), len(np.unique(product_ids))))\n",
    "\n",
    "# Create a mapping from customer and product IDs to internal indices\n",
    "customer_id_mapping = pd.Series(index=filtered_df['customer_id'].unique(), data=np.unique(customer_ids))\n",
    "product_id_mapping = pd.Series(index=filtered_df['product_id'].unique(), data=np.unique(product_ids))\n",
    "\n",
    "# Compute cosine similarity between items based on the sparse matrix\n",
    "item_similarity = cosine_similarity(pivot_table_sparse.T, dense_output=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_products_collaborative(customer_id, top_n=5):\n",
    "    # Function to recommend products to a customer based on collaborative filtering\n",
    "\n",
    "    # Check if the customer ID exists in the mapping, raise an error if not found\n",
    "    if customer_id not in customer_id_mapping.index:\n",
    "    if customer_id not in customer_id_mapping.index:\n",
    "        raise ValueError(f\"Customer ID '{customer_id}' not found in the mapping.\")\n",
    "\n",
    "    # Find the internal index of the customer in the similarity matrix\n",
    "    customer_idx = customer_id_mapping[customer_id]\n",
    "\n",
    "    # Get ratings (interactions) for the customer\n",
    "    customer_ratings = pivot_table_sparse[customer_idx].reshape(1, -1)\n",
    "\n",
    "    print(\"Dimensions of item_similarity:\", item_similarity.shape)\n",
    "    print(\"Dimensions of customer_ratings:\", customer_ratings.shape)\n",
    "\n",
    "    # Compute the weighted sum of similarity values for all items\n",
    "    weighted_sum = item_similarity.dot(customer_ratings.T)\n",
    "\n",
    "    # Get indices of products already purchased by the customer\n",
    "    purchased_product_indices = product_ids[customer_ratings.nonzero()[1]]\n",
    "\n",
    "    # Exclude already purchased products from the recommendations by setting their scores to 0\n",
    "    weighted_sum[purchased_product_indices] = 0\n",
    "    print(weighted_sum)\n",
    "    print('--------')\n",
    "    print(top_n)\n",
    "\n",
    "    \n",
    "    # Determine the top N products based on the similarity scores\n",
    "    top_n = min(top_n, weighted_sum.shape[0])\n",
    "    kth = min(top_n, weighted_sum.shape[0]) - 1\n",
    "    kth = max(0, kth)  # Ensure kth is not negative\n",
    "    \n",
    "    # Select the top N products, handle cases where kth might be out of bounds\n",
    "    if kth < len(weighted_sum.data):\n",
    "        top_product_indices = np.argpartition(weighted_sum.data, kth)[:kth + 1]\n",
    "        top_products = product_id_mapping.iloc[weighted_sum.indices[top_product_indices]].index\n",
    "    else:\n",
    "        # Handle the case when kth is out of bounds\n",
    "        top_products = product_id_mapping.index\n",
    "    \n",
    "    return top_products[:top_n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the test of our collaborative filtering recommendation system, a random customer ID was selected from the dataset to simulate a real-world scenario. The recommend_products_collaborative function generated personalized product recommendations based on this customer's previous interactions and the preferences of similar customers. The output included the dimensions of the similarity matrices and a list of five recommended product IDs. This brief test demonstrated the system's ability to leverage user-item interactions to provide tailored recommendations, validating its functionality and effectiveness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of item_similarity: (2000, 2000)\n",
      "Dimensions of customer_ratings: (1, 2000)\n",
      "  (741, 0)\t0.0\n",
      "  (927, 0)\t1.0324840195920109\n",
      "  (1287, 0)\t30.000000000000007\n",
      "--------\n",
      "5\n",
      "Collaborative Filtering Recommendations: Index(['595fac2a385ac33a80bd5114aec74eb8', '65266b2da20d04dbe00c5c2d3bb7859e',\n",
      "       '060cb19345d90064d1015407193c233d', '4520766ec412348b8d4caa5e8a18c464',\n",
      "       '08574b074924071f4e201e151b152b4e'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Testing the function with a random customer ID from the filtered dataset\n",
    "\n",
    "random_customer_id = filtered_df['customer_id'].sample().iloc[0]\n",
    "recommendations_collaborative = recommend_products_collaborative(random_customer_id)\n",
    "print(\"Collaborative Filtering Recommendations:\", recommendations_collaborative)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
